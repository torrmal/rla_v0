<head>
  <title>training_app</title>
  <style>
.layer {
  border: 1px solid #999;
  margin-bottom: 5px;
  text-align: left;
  padding: 10px;
}
.layer_act {
  width: 500px;
  float: right;
}
.ltconv {
  background-color: #FDD;
}
.ltrelu {
  background-color: #FDF;
}
.ltpool {
  background-color: #DDF;
}
.ltsoftmax {
  background-color: #FFD;
}
.ltfc {
  background-color: #DFF;
}
.ltlrn {
  background-color: #DFD; 
}
.ltitle {
  color: #333;
  font-size: 18px;
}
.actmap {
  margin: 1px;
}
#trainstats {
  text-align: left;
}
.clear {
  clear: both;
}
#wrap {
  width: 800px;
  margin-left: auto;
  margin-right: auto;
}
h1 {
  font-size: 16px;
  color: #333;
  background-color: #DDD;
  border-bottom: 1px #999 solid;
  text-align: center;
}
.secpart {
  width: 400px;
  float: left;
}
#lossgraph {
  /*border: 1px solid #F0F;*/
  width: 100%;
}
.probsdiv canvas {
  float: left;
}
.probsdiv {
  height: 60px;
  width: 180px;
  display: inline-block;
  font-size: 12px;
  box-shadow: 0px 0px 2px 2px #EEE;
  margin: 5px;
  padding: 5px;
  color: black;
}
.pp {
  margin: 1px;
  padding: 1px;
}
#testset_vis {
  margin-bottom: 200px;
}
body {
  font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
}
</style>

<script src="/src/trainerd_9_class_clean.js"></script>

<script src="/build/vis.js"></script>
<script src="/build/util.js"></script>
<script src="/build/convnet.js"></script>



<script>

var layer_defs, net, trainer;
var just_test = false;

var sampler_function = 'get_face_no_face';
var class_var_name = 'classes_txt_face';
var labeler_function = 'get_face_labels';

var classes_txt_face = [
  'face',
  'undefined'
];

var classes_txt_gender = [
  'Male',
  'Female',
];

var classes_txt = window[class_var_name];

var t = "layer_defs = [];\n\
layer_defs.push({type:'input', out_sx:32, out_sy:32, out_depth:3});\n\
layer_defs.push({type:'conv', sx:6, filters:5, stride:1, pad:2, activation:'relu'});\n\
layer_defs.push({type:'pool', sx:2, stride:2});\n\
layer_defs.push({type:'fc', filters:200, activation:'relu'});\n\
layer_defs.push({type:'softmax', num_classes:"+classes_txt.length+"});\n\
\n\
net = new convnetjs.Net();\n\
net.makeLayers(layer_defs);\n\
\n\
trainer = new convnetjs.SGDTrainer(net, {method:'adadelta', batch_size:32, l2_decay:0.001});\n\
";

// ------------------------
// BEGIN MNIST SPECIF1C STUFF
// ------------------------

var get_face_labels = function(item){
  return  item['gender'] == 'none'? 1 : 0;
}

var get_male_female_labels = function(item){

  return  _.indexOf(classes_txt, item['gender']);
}


var use_validation_data = true;

var last_checked = 'none';

var get_face_no_face = function(){
    var what = function(gender){

      if(last_checked != 'none') gender = 'other';
      if( gender == last_checked ) return false;
     
      return true;
    }

    do{
        if(wrong_pipe.length <= 0 ){
          var bi = Math.floor(Math.random()*training_data.length);
        }
        else{
          //console.log(wrong_pipe)
          var bi = wrong_pipe[0];
          wrong_pipe.shift();
        }
    }while(what(training_data[bi]['gender']));
    last_checked = training_data[bi]['gender'] == 'none'? 'other' : 'none';
    console.log(last_checked);
    return bi;
}

var get_all_but_trash = function(){
  var what = function(gender){

      if(last_checked != 'none') gender = 'other';
      if( gender == last_checked ) return false;
     
      return true;
    }

    do{
        if(wrong_pipe.length <= 0 ){
          var bi = Math.floor(Math.random()*training_data.length);
        }
        else{
          //console.log(wrong_pipe)
          var bi = wrong_pipe[0];
          wrong_pipe.shift();
        }
    }while(training_data[bi]['gender'] == 'none');
    return bi;
}

var get_an_index = function(){
    return window[sampler_function]();
}

var get_label_x = function(item){
  return window[labeler_function](item);
}

var sample_training_instance = function(callback) {

  var  bi = get_an_index();
  
  
  var img  = new Image();
  var limg_data = false;

  img.onload = function() { 
    var data_canvas = document.createElement('canvas');
    data_canvas.width = 32;
    data_canvas.height = 32;
    var data_ctx = data_canvas.getContext("2d");
    data_ctx.drawImage(img, 0, 0); // copy it over... bit wasteful :(
    var alpha = (Math.random() * 0.5);
    var red = Math.floor((Math.random() * 50));
    var green = Math.floor((Math.random() * 50));
    var blue = Math.floor((Math.random() * 50));

    data_ctx.fillStyle = "rgba("+red+", "+green+", "+blue+", "+alpha+")";
    console.log("rgba("+red+", "+green+", "+blue+", "+alpha+")");

    data_ctx.fillRect(0, 0, 32, 32);
    //data_ctx.rotate(20*Math.PI/180);
    data_ctx.save();
    limg_data = data_ctx.getImageData(0, 0, 32, 32);
    var p = limg_data.data;
    var x = new convnetjs.Vol(32,32,3,0.0);
    var W = 32*32;
    var j=0;
    for(var dc=0;dc<3;dc++) {
      var i=0;
      for(var xc=0;xc<32;xc++) {
        for(var yc=0;yc<32;yc++) {
          var ix = ( i) * 4 + dc;
          x.set(yc,xc,dc,p[ix]/255.0-0.5);
          i++;
        }
      }
    }
    var dx = Math.floor(Math.random()*5-2);
    var dy = Math.floor(Math.random()*5-2);
   // x = convnetjs.augment(x, 32, dx, dy, Math.random()<0.5);
    //var isval = use_validation_data && n%10===0 ? true : false;
   var lbl =  get_label_x(training_data[bi]);
    //var lbl = _.indexOf(classes_txt, training_data[bi]['gender']+':'+training_data[bi]['age_group']);
    
    callback({x:x, label:lbl, isval:false});
  };
  img.src = training_data[bi]['file'];


 

  
}

// sample a random testing instance
var sample_test_instance = function(callback) {

  // find an unloaded batch
  //do{
    var  bi = get_an_index();
  //}while(training_data[bi]['gender']=='none' || training_data[bi]['gender']=='Female')
  
  var img  = new Image();
  var limg_data = false;
  img.onload = function() { 
    var data_canvas = document.createElement('canvas');
    data_canvas.width = 32;
    data_canvas.height = 32;
    var data_ctx = data_canvas.getContext("2d");
    data_ctx.drawImage(img, 0, 0); // copy it over... bit wasteful :(
     var alpha = (Math.random() * 0.6);
    var red = Math.floor((Math.random() * 100));
    var green = Math.floor((Math.random() * 100));
    var blue = Math.floor((Math.random() * 100));
    data_ctx.fillStyle = "rgba("+red+", "+green+", "+blue+", "+alpha+")";
    data_ctx.fillRect(0, 0, 32, 32);
    //data_ctx.rotate(20*Math.PI/180);
    data_ctx.save();
    limg_data = data_ctx.getImageData(0, 0, 32, 32);
    var p = limg_data.data;
    var x = new convnetjs.Vol(32,32,3,0.0);
    var W = 32*32;
    var j=0;
    for(var dc=0;dc<3;dc++) {
      var i=0;
      for(var xc=0;xc<32;xc++) {
        for(var yc=0;yc<32;yc++) {
          var ix = ( i) * 4 + dc;
          x.set(yc,xc,dc,p[ix]/255.0-0.5);
          i++;
        }
      }
    }
    

    var xs = [];
    //xs.push(x, 32, 0, 0, false); // push an un-augmented copy
    for(var k=0;k<6;k++) {
      var dx = Math.floor(Math.random()*5-2);
      var dy = Math.floor(Math.random()*5-2);
      xs.push(convnetjs.augment(x, 32, dx, dy, k>2));
    }
    
    // return multiple augmentations, and we will average the network over them
    // to increase performance
    var lbl =  get_label_x(training_data[bi]);
    //var lbl = _.indexOf(classes_txt, training_data[bi]['gender']+':'+training_data[bi]['age_group']);
     /**var lbl = training_data[bi]['age_group'] == '0_18'? 0:
              training_data[bi]['age_group'] == '18_35'? 1:
              training_data[bi]['age_group'] == '35_55'? 2:
              3; **/
    callback( {x:xs, label:lbl} , bi);
   // x = convnetjs.augment(x, 32, dx, dy, Math.random()<0.5);
    //var isval = use_validation_data && n%10===0 ? true : false;
    //callback({x:x, label:training_data[bi]['gender'], isval:false});
  };
  img.src = training_data[bi]['file'];

  
}

var num_batches = 51; // 20 training batches, 1 test
var test_batch = 50;
var data_img_elts = new Array(num_batches);
var img_data = new Array(num_batches);
var loaded = new Array(num_batches);
var loaded_train_batches = [];
var training_data = [];
// int main
$(window).load(function() {
  //alert('asfsd');
  $.getJSON( "/src/train_data.json", function( data ) {
    training_data = data;
  });
  $("#newnet").val(t);
  eval($("#newnet").val());
  
  update_net_param_display();

  for(var k=0;k<loaded.length;k++) { loaded[k] = false; }

  //load_data_batch(0); // async load train set batch 0 (6 total train batches)
  //load_data_batch(test_batch); // async load test set (batch 6)
  start_fun();
});

var start_fun = function() {
  //if(loaded[0] && loaded[test_batch]) { 
    console.log('starting!'); 
    if(!just_test){
       setInterval(load_and_step, 0); // lets go! 
    }
    else{
      setInterval(test_predict, 1000);
    }
    //
  //}
  //else { setTimeout(start_fun, 200); } // keep checking
}

var load_data_batch = function(batch_num) {
  // Load the dataset with JS in background
  data_img_elts[batch_num] = new Image();
  var data_img_elt = data_img_elts[batch_num];
  data_img_elt.onload = function() { 
    var data_canvas = document.createElement('canvas');
    data_canvas.width = data_img_elt.width;
    data_canvas.height = data_img_elt.height;
    var data_ctx = data_canvas.getContext("2d");
    data_ctx.drawImage(data_img_elt, 0, 0); // copy it over... bit wasteful :(
    img_data[batch_num] = data_ctx.getImageData(0, 0, data_canvas.width, data_canvas.height);
    loaded[batch_num] = true;
    if(batch_num < test_batch) { loaded_train_batches.push(batch_num); }
    console.log('finished loading data batch ' + batch_num);
  };
  data_img_elt.src = "cifar10/cifar10_batch_" + batch_num + ".png";
}

// ------------------------
// END MNIST SPECIFIC STUFF
// ------------------------

var maxmin = cnnutil.maxmin;
var f2t = cnnutil.f2t;

// elt is the element to add all the canvas activation drawings into
// A is the Vol() to use
// scale is a multiplier to make the visualizations larger. Make higher for larger pictures
// if grads is true then gradients are used instead
var draw_activations = function(elt, A, scale, grads) {

  var s = scale || 2; // scale
  var draw_grads = false;
  if(typeof(grads) !== 'undefined') draw_grads = grads;

  // get max and min activation to scale the maps automatically
  var w = draw_grads ? A.dw : A.w;
  var mm = maxmin(w);

  // create the canvas elements, draw and add to DOM
  for(var d=0;d<A.depth;d++) {

    var canv = document.createElement('canvas');
    canv.className = 'actmap';
    var W = A.sx * s;
    var H = A.sy * s;
    canv.width = W;
    canv.height = H;
    var ctx = canv.getContext('2d');
    var g = ctx.createImageData(W, H);

    for(var x=0;x<A.sx;x++) {
      for(var y=0;y<A.sy;y++) {
        if(draw_grads) {
          var dval = Math.floor((A.get_grad(x,y,d)-mm.minv)/mm.dv*255);
        } else {
          var dval = Math.floor((A.get(x,y,d)-mm.minv)/mm.dv*255);  
        }
        for(var dx=0;dx<s;dx++) {
          for(var dy=0;dy<s;dy++) {
            var pp = ((W * (y*s+dy)) + (dx + x*s)) * 4;
            for(var i=0;i<3;i++) { g.data[pp + i] = dval; } // rgb
            g.data[pp+3] = 255; // alpha channel
          }
        }
      }
    }
    ctx.putImageData(g, 0, 0);
    elt.appendChild(canv);
  }  
}

var draw_activations_COLOR = function(elt, A, scale, grads) {

  var s = scale || 2; // scale
  var draw_grads = false;
  if(typeof(grads) !== 'undefined') draw_grads = grads;

  // get max and min activation to scale the maps automatically
  var w = draw_grads ? A.dw : A.w;
  var mm = maxmin(w);

  var canv = document.createElement('canvas');
  canv.className = 'actmap';
  var W = A.sx * s;
  var H = A.sy * s;
  canv.width = W;
  canv.height = H;
  var ctx = canv.getContext('2d');
  var g = ctx.createImageData(W, H);
  for(var d=0;d<3;d++) {
    for(var x=0;x<A.sx;x++) {
      for(var y=0;y<A.sy;y++) {
        if(draw_grads) {
          var dval = Math.floor((A.get_grad(x,y,d)-mm.minv)/mm.dv*255);
        } else {
          var dval = Math.floor((A.get(x,y,d)-mm.minv)/mm.dv*255);  
        }
        for(var dx=0;dx<s;dx++) {
          for(var dy=0;dy<s;dy++) {
            var pp = ((W * (y*s+dy)) + (dx + x*s)) * 4;
            g.data[pp + d] = dval;
            if(d===0) g.data[pp+3] = 255; // alpha channel
          }
        }
      }
    }
  }
  ctx.putImageData(g, 0, 0);
  elt.appendChild(canv);
}

var visualize_activations = function(net, elt) {

  // clear the element
  elt.innerHTML = "";

  // show activations in each layer
  var N = net.layers.length;
  for(var i=0;i<N;i++) {
    var L = net.layers[i];

    var layer_div = document.createElement('div');

    // visualize activations
    var activations_div = document.createElement('div');
    activations_div.appendChild(document.createTextNode('Activations:'));
    activations_div.appendChild(document.createElement('br'));
    activations_div.className = 'layer_act';
    var scale = 2;
    if(L.layer_type==='softmax' || L.layer_type==='fc') scale = 10; // for softmax
    
    // HACK to draw in color in input layer
    if(i===0) {
      draw_activations_COLOR(activations_div, L.out_act, scale);
      draw_activations_COLOR(activations_div, L.out_act, scale, true);

      /*
      // visualize positive and negative components of the gradient separately
      var dd = L.out_act.clone();
      var ni = L.out_act.w.length;
      for(var q=0;q<ni;q++) { var dwq = L.out_act.dw[q]; dd.w[q] = dwq > 0 ? dwq : 0.0; }
      draw_activations_COLOR(activations_div, dd, scale);
      for(var q=0;q<ni;q++) { var dwq = L.out_act.dw[q]; dd.w[q] = dwq < 0 ? -dwq : 0.0; }
      draw_activations_COLOR(activations_div, dd, scale);
      */

      /*
      // visualize what the network would like the image to look like more
      var dd = L.out_act.clone();
      var ni = L.out_act.w.length;
      for(var q=0;q<ni;q++) { var dwq = L.out_act.dw[q]; dd.w[q] -= 20*dwq; }
      draw_activations_COLOR(activations_div, dd, scale);
      */

      /*
      // visualize gradient magnitude
      var dd = L.out_act.clone();
      var ni = L.out_act.w.length;
      for(var q=0;q<ni;q++) { var dwq = L.out_act.dw[q]; dd.w[q] = dwq*dwq; }
      draw_activations_COLOR(activations_div, dd, scale);
      */

    } else {
      draw_activations(activations_div, L.out_act, scale);
    } 

    // visualize filters if they are of reasonable size
    if(L.layer_type === 'conv') {
      var filters_div = document.createElement('div');
      if(L.filters[0].sx>3) {
        // actual weights
        filters_div.appendChild(document.createTextNode('Weights:'));
        filters_div.appendChild(document.createElement('br'));
        for(var j=0;j<L.filters.length;j++) {
          // HACK to draw in color for first layer conv filters
          if(i===1) draw_activations_COLOR(filters_div, L.filters[j], 2);
          else draw_activations(filters_div, L.filters[j], 2);
        }
        // gradients
        filters_div.appendChild(document.createElement('br'));
        filters_div.appendChild(document.createTextNode('Gradients:'));
        filters_div.appendChild(document.createElement('br'));
        for(var j=0;j<L.filters.length;j++) {
          if(i===1) draw_activations_COLOR(filters_div, L.filters[j], 2, true);
          else draw_activations(filters_div, L.filters[j], 2, true);
        }
      } else {
        filters_div.appendChild(document.createTextNode('Weights hidden, too small'));
      }
      activations_div.appendChild(filters_div);
    }
    layer_div.appendChild(activations_div);

    // print some stats on left of the layer
    layer_div.className = 'layer ' + 'lt' + L.layer_type;
    var title_div = document.createElement('div');
    title_div.className = 'ltitle'
    var t = L.layer_type + ' (' + L.out_sx + 'x' + L.out_sy + 'x' + L.out_depth + ')';
    title_div.appendChild(document.createTextNode(t));
    layer_div.appendChild(title_div);

    if(L.layer_type==='conv') {
      var t = 'filter size ' + L.filters[0].sx + 'x' + L.filters[0].sy + 'x' + L.filters[0].depth + ', stride ' + L.stride;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }
    if(L.layer_type==='pool') {
      var t = 'pooling size ' + L.sx + 'x' + L.sy + ', stride ' + L.stride;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }

    // find min, max activations and display them
    var mma = maxmin(L.out_act.w);
    var t = 'max activation: ' + f2t(mma.maxv) + ', min: ' + f2t(mma.minv);
    layer_div.appendChild(document.createTextNode(t));
    layer_div.appendChild(document.createElement('br'));

    // number of parameters
    if(L.layer_type==='conv' || L.layer_type==='local') {
      var tot_params = L.sx*L.sy*L.in_depth*L.filters.length + L.filters.length;
      var t = 'parameters: ' + L.filters.length + 'x' + L.sx + 'x' + L.sy + 'x' + L.in_depth + '+' + L.filters.length + ' = ' + tot_params;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }
    if(L.layer_type==='fc') {
      var tot_params = L.num_inputs*L.filters.length + L.filters.length;
      var t = 'parameters: ' + L.filters.length + 'x' + L.num_inputs + '+' + L.filters.length + ' = ' + tot_params;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }

    // css madness needed here...
    var clear = document.createElement('div');
    clear.className = 'clear';
    layer_div.appendChild(clear);

    elt.appendChild(layer_div);
  }
}

// loads a training image and trains on it with the network
var paused = false;
var load_and_step = function() {
  if(paused) return; 

  var sample = sample_training_instance(step);
  //step(sample); // process this image
  
  //setTimeout(load_and_step, 0); // schedule the next iteration
}

var wrong_pipe = [];
// evaluate current network on test set
var test_predict = function() {
  var num_classes = net.layers[net.layers.length-1].out_depth;

  document.getElementById('testset_acc').innerHTML = '';
  var num_total = 0;
  var num_correct = 0;

  var bist = function(num){
    var test_step = function(sample, index_in){
       var y = sample.label;  // ground truth label

      // forward prop it through the network
      var aavg = new convnetjs.Vol(1,1,num_classes,0.0);
      // ensures we always have a list, regardless if above returns single item or list
      var xs = [].concat(sample.x);
      var n = xs.length;
      for(var i=0;i<n;i++) {
        var a = net.forward(xs[i]);
        aavg.addFrom(a);
      }
      var preds = [];
      for(var k=0;k<aavg.w.length;k++) { preds.push({k:k,p:aavg.w[k]}); }
      preds.sort(function(a,b){return a.p<b.p ? 1:-1;});
      
      var correct = preds[0].k===y;
      if(correct) num_correct++;
      else{
        //console.log(index_in);
        wrong_pipe.push(index_in);
        wrong_pipe.push(index_in);
        wrong_pipe.push(index_in);
      }
      num_total++;

      var div = document.createElement('div');
      div.className = 'testdiv';

      // draw the image into a canvas
      draw_activations_COLOR(div, xs[0], 2); // draw Vol into canv

      // add predictions
      var probsdiv = document.createElement('div');
      div.className = 'probsdiv';
      var t = '';
      var nlimit = aavg.w.length > 3 ? 3: aavg.w.length;
      for(var k=0;k<nlimit;k++) {
        //console.log(k);
        //console.log(preds);
        var col = preds[k].k===y ? 'rgb(85,187,85)' : 'rgb(187,85,85)';
        t += '<div class=\"pp\" style=\"width:' + Math.floor(preds[k].p/n*100) + 'px; margin-left: 70px; background-color:' + col + ';\">' + classes_txt[preds[k].k] + '</div>'
      }
      probsdiv.innerHTML = t;
      div.appendChild(probsdiv);

      // add it into DOM
      $(div).prependTo($("#testset_vis")).hide().fadeIn('slow').slideDown('slow');
      if($(".probsdiv").length>200) {
        $("#testset_vis > .probsdiv").last().remove(); // pop to keep upper bound of shown items
      }
      if(num >= 3){
        testAccWindow.add(num_correct/num_total);
        $("#testset_acc").text('test accuracy based on last 200 test images: ' + testAccWindow.get_average());  

      }
    }
    return test_step;
  }
  // grab a random test image
  for(num=0;num<4;num++) {
    sample_test_instance(bist(num));

   
  }
}

var lossGraph = new cnnvis.Graph();
var xLossWindow = new cnnutil.Window(100);
var wLossWindow = new cnnutil.Window(100);
var trainAccWindow = new cnnutil.Window(100);
var valAccWindow = new cnnutil.Window(100);
var testAccWindow = new cnnutil.Window(50, 1);
var step_num = 0;

var step = function(sample) {

  var x = sample.x;
  var y = sample.label;

  

  // train on it with network
  var stats = trainer.train(x, y);
  var lossx = stats.cost_loss;
  var lossw = stats.l2_decay_loss;

  // keep track of stats such as the average training error and loss
  var yhat = net.getPrediction();
  var train_acc = yhat === y ? 1.0 : 0.0;
  xLossWindow.add(lossx);
  wLossWindow.add(lossw);
  trainAccWindow.add(train_acc);

  // visualize training status
  var train_elt = document.getElementById("trainstats");
  train_elt.innerHTML = '';
  var t = 'Forward time per example: ' + stats.fwd_time + 'ms';
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Backprop time per example: ' + stats.bwd_time + 'ms';
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Classification loss: ' + f2t(xLossWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'L2 Weight decay loss: ' + f2t(wLossWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Training accuracy: ' + f2t(trainAccWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Validation accuracy: ' + f2t(valAccWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Examples seen: ' + step_num;
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));

  // visualize activations
  if(step_num % 100 === 0) {
    var vis_elt = document.getElementById("visnet");
    visualize_activations(net, vis_elt);
  }

  // log progress to graph, (full loss)
  if(step_num % 200 === 0) {
    var xa = xLossWindow.get_average();
    var xw = wLossWindow.get_average();
    if(xa >= 0 && xw >= 0) { // if they are -1 it means not enough data was accumulated yet for estimates
      lossGraph.add(step_num, xa + xw);
      lossGraph.drawSelf(document.getElementById("lossgraph"));
    }
  }

  // run prediction on test set
  if((step_num % 100 === 0 && step_num > 0) || step_num===100) {
    test_predict();
  }
  step_num++;
}

// user settings 
var change_lr = function() {
  trainer.learning_rate = parseFloat(document.getElementById("lr_input").value);
  update_net_param_display();
}
var change_momentum = function() {
  trainer.momentum = parseFloat(document.getElementById("momentum_input").value);
  update_net_param_display();
}
var change_batch_size = function() {
  trainer.batch_size = parseFloat(document.getElementById("batch_size_input").value);
  update_net_param_display();
}
var change_decay = function() {
  trainer.l2_decay = parseFloat(document.getElementById("decay_input").value);
  update_net_param_display();
}
var update_net_param_display = function() {
  document.getElementById('lr_input').value = trainer.learning_rate;
  document.getElementById('momentum_input').value = trainer.momentum;
  document.getElementById('batch_size_input').value = trainer.batch_size;
  document.getElementById('decay_input').value = trainer.l2_decay;
}
var toggle_pause = function() {
  paused = !paused;
  var btn = document.getElementById('buttontp');
  if(paused) { btn.value = 'resume' }
  else { btn.value = 'pause'; }
}
var dump_json = function() {
  console.log( JSON.stringify(this.net.toJSON()) );
}
var clear_graph = function() {
  lossGraph = new cnnvis.Graph(); // reinit graph too 
}
var reset_all = function() {
  // reinit trainer
  trainer = new convnetjs.SGDTrainer(net, {learning_rate:trainer.learning_rate, momentum:trainer.momentum, batch_size:trainer.batch_size, decay:trainer.l2_decay});
  update_net_param_display();

  // reinit windows that keep track of val/train accuracies
  xLossWindow.reset();
  wLossWindow.reset();
  trainAccWindow.reset();
  valAccWindow.reset();
  testAccWindow.reset();
  lossGraph = new cnnvis.Graph(); // reinit graph too
  step_num = 0;
}
var load_from_json = function() {
  //var jsonString = document.getElementById("dumpjson").value;
  var json = trained_l;
  console.log(json);//JSON.parse(jsonString);
  net = new convnetjs.Net();
  net.fromJSON(json);
  reset_all();

}
var change_net = function() {
  eval($("#newnet").val());
  reset_all();
}

</script>

</head>

<body>
  {{> hello}}
</body>

<template name="hello">
  
  <div id="wrap">
  
 
  
  <h1>Training Stats</h1>
  <div class="divsec" style="270px;">
    <div class="secpart">
      Current image: <img id="input_image" src=""/>
      <input id="buttontp" type="submit" value="pause" onclick="toggle_pause();"/>
      <div id="trainstats"></div>

      <div id="controls">
        Learning rate: <input name="lri" type="text" maxlength="20" id="lr_input"/>
        <input id="buttonlr" type="submit" value="change" onclick="change_lr();"/>
        <br />

        Momentum: <input name="momi" type="text" maxlength="20" id="momentum_input"/>
        <input id="buttonmom" type="submit" value="change" onclick="change_momentum();"/>
        <br />

        Batch size: <input name="bsi" type="text" maxlength="20" id="batch_size_input"/>
        <input id="buttonbs" type="submit" value="change" onclick="change_batch_size();"/>
        <br />

        Weight decay: <input name="wdi" type="text" maxlength="20" id="decay_input"/>
        <input id="buttonwd" type="submit" value="change" onclick="change_decay();"/>
      </div>

      <input id="buttondj" type="submit" value="save network snapshot as JSON" onclick="dump_json();"/><br />
      <input id="buttonlfj" type="submit" value="init network from JSON snapshot" onclick="load_from_json();"/><br />
      <textarea id="dumpjson"></textarea>
    </div>
    <div class="secpart">
      
      <div>
        Loss:<br />
        <canvas id="lossgraph">
        </canvas>
        <br />
        <input id="buttoncg" type="submit" value="clear graph" onclick="clear_graph();"/>
      </div>
    </div>
    <div style="clear:both;"></div>
  </div>

  <h1>Instantiate a Network and Trainer</h1>
  <div>
    <textarea id="newnet" style="width:100%; height:200px;"></textarea><br />
    <input id="buttonnn" type="submit" value="change network" onclick="change_net();" style="width:200px;height:30px;"/>
  </div>

  <div class="divsec">
  <h1>Network Visualization</h1>
    <div id="visnet"></div>
  </div>
  
  <div class="divsec">
  <h1>Example predictions on Test set</h1>
    <div id="testset_acc"></div>
    <div id="testset_vis"></div>
  </div>

  </div> 
</template>
 



